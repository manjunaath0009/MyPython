{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manjunaath0009/MyPython/blob/master/language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-DXBFrotCQJ"
      },
      "source": [
        "# Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kX8WYcJtCQK"
      },
      "source": [
        "- Create the traditinal ngram-based language model\n",
        "- Codes from [A comprehensive guide to build your own language model in python](https://medium.com/analytics-vidhya/a-comprehensive-guide-to-build-your-own-language-model-in-python-5141b3917d6d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHk-AIKFtCQK"
      },
      "source": [
        "## Training a Trigram Language Model using Reuters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "BAJOFiM8CpWw",
        "outputId": "b9bbf6e4-740e-40ac-8bbe-900feabaa59c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bxN7Dh4DtCQL",
        "outputId": "57ff994b-617c-4e12-a719-617f114cd410",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11.5 s, sys: 699 ms, total: 12.2 s\n",
            "Wall time: 12.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# code courtesy of https://nlpforhackers.io/language-models/\n",
        "\n",
        "from nltk.corpus import reuters\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Create a placeholder for model\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "# Count frequency of co-occurance\n",
        "for sentence in reuters.sents():\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "        model[(w1, w2)][w3] += 1\n",
        "\n",
        "# Let's transform the counts to probabilities\n",
        "for w1_w2 in model:\n",
        "    total_count = float(sum(model[w1_w2].values()))\n",
        "    for w3 in model[w1_w2]:\n",
        "        model[w1_w2][w3] /= total_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAh1Fy-4tCQL"
      },
      "source": [
        "## Check Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ts30A1w8tCQL",
        "outputId": "fe0b1bf4-4707-4572-f10c-f1535311e6d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('conference', 0.25),\n",
              " ('of', 0.125),\n",
              " ('.', 0.125),\n",
              " ('with', 0.08333333333333333),\n",
              " (',', 0.08333333333333333),\n",
              " ('agency', 0.08333333333333333),\n",
              " ('that', 0.08333333333333333),\n",
              " ('brought', 0.041666666666666664),\n",
              " ('about', 0.041666666666666664),\n",
              " ('broke', 0.041666666666666664),\n",
              " ('on', 0.041666666666666664)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "sorted(dict(model[\"the\",\"news\"]).items(), key=lambda x:-1*x[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhSjwIL8tCQL"
      },
      "source": [
        "## Text Generation Using the Trigram Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak5qcAHqtCQM"
      },
      "source": [
        "- Using the trigram model to predict the next word.\n",
        "- The prediction is based on the predicted probability distribution of the next words: words above a predefined cut-off are randomly selected.\n",
        "- The text generator ends when two consecutuve None's are predicted (signaling the end of the sentence)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dnQ8OiCntCQM",
        "outputId": "c6e7e204-ce39-437c-fb0c-b036cc7b59c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the news , dipping on its enforcement staff .\n"
          ]
        }
      ],
      "source": [
        "# code courtesy of https://nlpforhackers.io/language-models/\n",
        "import random\n",
        "# https://alvinntnu.github.io/python-notes/nlp/language-model.html\n",
        "\n",
        "# starting words\n",
        "text = [\"the\", \"news\"]\n",
        "sentence_finished = False\n",
        "\n",
        "while not sentence_finished:\n",
        "  # select a random probability threshold\n",
        "  r = random.random()\n",
        "  accumulator = .0\n",
        "\n",
        "  for word in model[tuple(text[-2:])].keys():\n",
        "      accumulator += model[tuple(text[-2:])][word]\n",
        "      # select words that are above the probability threshold\n",
        "      if accumulator >= r:\n",
        "          text.append(word)\n",
        "          break\n",
        "\n",
        "  if text[-2:] == [None, None]:\n",
        "      sentence_finished = True\n",
        "\n",
        "print (' '.join([t for t in text if t]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"This is a sample sentence, showing off the stop words filtration.\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "# Regular expression to match punctuation\n",
        "cleaned_tokens = [re.sub(r'[^\\w\\s]', '', token) for token in tokens if re.sub(r'[^\\w\\s]', '', token)]\n",
        "print(cleaned_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty9PeM_yklik",
        "outputId": "1c748a81-5c7a-4c1a-cf2f-c6b33fd3f212"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'sample', 'sentence', 'showing', 'off', 'the', 'stop', 'words', 'filtration']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcit8ozktCQM"
      },
      "source": [
        "## Issues of Ngram Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHjpX0ZEtCQM"
      },
      "source": [
        "- The ngram size is of key importance. The higher the order of the ngram, the better the prediction. But it comes with the issues of computation overload and data sparceness.\n",
        "- Unseen ngrams are always a concern.\n",
        "- Probability smoothing issues.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thYrI7BOtCQM"
      },
      "source": [
        "## Neural Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNhJOYI5tCQM"
      },
      "source": [
        "- Neural language model based on deep learning may provide a better alternative to model the probabilistic relationships of linguistic units."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_n_grams(data, n, start_token = \"<s>\", end_token = \"<e>\") -> 'dict':\n",
        "\n",
        "  # Empty dict for n-grams\n",
        "  n_grams = {}\n",
        "\n",
        "  # Iterate over all sentences in the dataset\n",
        "  for sentence in data:\n",
        "\n",
        "    # Append n start tokens and a single end token to the sentence\n",
        "    sentence = [start_token]*n + sentence + [end_token]\n",
        "\n",
        "    # Convert the sentence into a tuple\n",
        "    sentence = tuple(sentence)\n",
        "\n",
        "    # Temp var to store length from start of n-gram to end\n",
        "    m = len(sentence) if n==1 else len(sentence)-1\n",
        "\n",
        "    # Iterate over this length\n",
        "    for i in range(m):\n",
        "\n",
        "      # Get the n-gram\n",
        "      n_gram = sentence[i:i+n]\n",
        "\n",
        "      # Add the count of n-gram as value to our dictionary\n",
        "      # IF n-gram is already present\n",
        "      if n_gram in n_grams.keys():\n",
        "        n_grams[n_gram] += 1\n",
        "      # Add n-gram count\n",
        "      else:\n",
        "        n_grams[n_gram] = 1\n",
        "\n",
        "  return n_grams"
      ],
      "metadata": {
        "id": "LzwD-TpThN3Q"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python-notes",
      "language": "python",
      "name": "python-notes"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}